{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calling a.k.a Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling say_hello\n",
      "say_hello took 0.000033 seconds to process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Saurabh, your age is 10.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Decorators Refresher\n",
    "\"\"\"\n",
    "By definition, a decorator is a function that takes another function \n",
    "and extends the behavior of the latter function without explicitly modifying it\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        starttime = time.perf_counter()\n",
    "        print(f\"Calling {func.__name__}\")\n",
    "        value = func(*args, **kwargs)\n",
    "        endtime = time.perf_counter()\n",
    "        time_taken = endtime - starttime\n",
    "        print(f\"{func.__name__} took {time_taken:4f} seconds to process\")\n",
    "        return value\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def say_hello(name,age):\n",
    "    return f\"Hello {name}, your age is {age}.\"\n",
    "\n",
    "say_hello(\"Saurabh\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using @tool decorator\n",
    "\n",
    "While the name implies that the model is performing some action, this is actually <b><u>not</u></b> the case!\n",
    "The model is coming up with the arguments to a tool, and actually running the tool.\n",
    "\n",
    "Chat models supporting tool calling features implement a .bind_tools method, which receives a list of LangChain tool objects and binds them to the chat model in its expected format. Subsequent invocations of the chat model will include tool schemas in its calls to the LLM.\n",
    "\n",
    "Tool Decorator makes tools out of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b:int)->int:\n",
    "    \"Multiply a & b\"\n",
    "    return a*b\n",
    "\n",
    "@tool\n",
    "def add(a:int, b:int)->int:\n",
    "    \"Add a & b\"\n",
    "    return a+b\n",
    "\n",
    "tools = [multiply,add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or using pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just an example way of writing the code, these functions don't return anything\n",
    "# In the below code, only above functions are used.\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Add(BaseModel):\n",
    "    \"\"\"Add two integers together.\"\"\"\n",
    "    a:int=Field(...,description=\"First integer\")\n",
    "    b:int=Field(...,description=\"Second Integer\")\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    a:int=Field(...,description=\"First integer\")\n",
    "    b:int=Field(...,description=\"Second Integer\")\n",
    "\n",
    "tools = [Add, Multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM.bind_tools()\n",
    "### llm_with_tools.invoke().tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1318a8f50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x133a45370>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='') kwargs={'tools': [{'type': 'function', 'function': {'name': 'Add', 'description': 'Add two integers together.', 'parameters': {'type': 'object', 'properties': {'a': {'description': 'First integer', 'type': 'integer'}, 'b': {'description': 'Second Integer', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'Multiply', 'description': 'Multiply two integers together.', 'parameters': {'type': 'object', 'properties': {'a': {'description': 'First integer', 'type': 'integer'}, 'b': {'description': 'Second Integer', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_ZNrCBkNKA0gtpiSDakHFoUw4', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_UvMqdwFS9K0AlvTCr9aIYxAL', 'function': {'arguments': '{\"a\": 3, \"b\": 3}', 'name': 'Add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 102, 'total_tokens': 152}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-3dca4117-d3a4-4949-ad38-61f626500868-0' tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_ZNrCBkNKA0gtpiSDakHFoUw4'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_UvMqdwFS9K0AlvTCr9aIYxAL'}]\n",
      "****************************************************************************************************\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_ZNrCBkNKA0gtpiSDakHFoUw4'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_UvMqdwFS9K0AlvTCr9aIYxAL'}]\n",
      "####################################################################################################\n",
      "LLM Result\n",
      "content='3*12 is equal to 36.\\n\\n3+3 is equal to 6.' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 22, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-2669d102-3f89-4df9-916e-a5289e83e270-0'\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "#bind_tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "print(llm_with_tools)\n",
    "\n",
    "query = \"What is 3*12? Also what is 3+3?\"\n",
    "\n",
    "\n",
    "# The role of LLM here is to just identify the right parameters and functions to call\n",
    "# LLM is not resolving the user query using below line of code\n",
    "result = llm_with_tools.invoke(query)\n",
    "print(result)\n",
    "print(\"**\"*50)\n",
    "print(result.tool_calls)\n",
    "\n",
    "\n",
    "\n",
    "# To make a call to LLM and get result of a query, we have to call LLM.invoke\n",
    "# This is the direct LLM call without the tools.\n",
    "print(\"##\"*50)\n",
    "print(f\"LLM Result\\n{llm.invoke(query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tool_calls is the main object that performs the major job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1318a8f50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x133a45370>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='') kwargs={'tools': [{'type': 'function', 'function': {'name': 'Add', 'description': 'Add two integers together.', 'parameters': {'type': 'object', 'properties': {'a': {'description': 'First integer', 'type': 'integer'}, 'b': {'description': 'Second Integer', 'type': 'integer'}}, 'required': ['a', 'b']}}}, {'type': 'function', 'function': {'name': 'Multiply', 'description': 'Multiply two integers together.', 'parameters': {'type': 'object', 'properties': {'a': {'description': 'First integer', 'type': 'integer'}, 'b': {'description': 'Second Integer', 'type': 'integer'}}, 'required': ['a', 'b']}}}]}\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_ZNrCBkNKA0gtpiSDakHFoUw4', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_UvMqdwFS9K0AlvTCr9aIYxAL', 'function': {'arguments': '{\"a\": 3, \"b\": 3}', 'name': 'Add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 102, 'total_tokens': 152}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-3dca4117-d3a4-4949-ad38-61f626500868-0' tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_ZNrCBkNKA0gtpiSDakHFoUw4'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_UvMqdwFS9K0AlvTCr9aIYxAL'}]\n",
      "****************************************************************************************************\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_ZNrCBkNKA0gtpiSDakHFoUw4'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_UvMqdwFS9K0AlvTCr9aIYxAL'}]\n",
      "####################################################################################################\n",
      "LLM Result\n",
      "content='3*12 is equal to 36.\\n\\n3+3 is equal to 6.' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 22, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-2669d102-3f89-4df9-916e-a5289e83e270-0'\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "#bind_tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "print(llm_with_tools)\n",
    "\n",
    "query = \"What is 3*12? Also what is 3+3?\"\n",
    "\n",
    "\n",
    "# The role of LLM here is to just identify the right parameters and functions to call\n",
    "# LLM is not resolving the user query using below line of code\n",
    "result = llm_with_tools.invoke(query)\n",
    "print(result)\n",
    "print(\"**\"*50)\n",
    "print(result.tool_calls)\n",
    "\n",
    "\n",
    "\n",
    "# To make a call to LLM and get result of a query, we have to call LLM.invoke\n",
    "# This is the direct LLM call without the tools.\n",
    "print(\"##\"*50)\n",
    "print(f\"LLM Result\\n{llm.invoke(query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Multiply(a=3, b=12), Add(a=3, b=3)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Output Parser to format the output\n",
    "# Convert the output back to original pydantic class\n",
    "\n",
    "# PydanticToolsParser needs a pydantic base class type of tools list\n",
    "\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "\n",
    "output_parser=PydanticToolsParser(tools=[Multiply, Add])\n",
    "\n",
    "chain = llm_with_tools | output_parser\n",
    "\n",
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing tool outputs to model\n",
    "Using ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing selected tool name='multiply' description='multiply(a: int, b: int) -> int - Multiply a & b' args_schema=<class 'pydantic.v1.main.multiplySchema'> func=<function multiply at 0x125131bc0>\n",
      "printing tool output 36\n",
      "printing selected tool name='add' description='add(a: int, b: int) -> int - Add a & bs' args_schema=<class 'pydantic.v1.main.addSchema'> func=<function add at 0x1251318a0>\n",
      "printing tool output 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3*12? Also what is 3+3?'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_WNGIvts2PNivb95FKu9kwKCb', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_0ONTAtbTj52W5oUDHJp17vpd', 'function': {'arguments': '{\"a\": 3, \"b\": 3}', 'name': 'Add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 90, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_caf95bb1ae', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a8185c01-48da-4cf9-9290-a7127ac59648-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_WNGIvts2PNivb95FKu9kwKCb'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_0ONTAtbTj52W5oUDHJp17vpd'}]),\n",
       " ToolMessage(content='36', tool_call_id='call_WNGIvts2PNivb95FKu9kwKCb'),\n",
       " ToolMessage(content='6', tool_call_id='call_0ONTAtbTj52W5oUDHJp17vpd')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage, HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=query)]\n",
    "ai_message = llm_with_tools.invoke(query)\n",
    "messages.append(ai_message)\n",
    "\n",
    "for tool_call in ai_message.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    print(f\"printing selected tool {selected_tool}\")\n",
    "    #It's on user when they want to invoke the tool\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    print(f\"printing tool output {tool_output}\")\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_EjJGiBt5QpJYyNmG3RNzCt36'},\n",
       " {'name': 'Add',\n",
       "  'args': {'a': 952, 'b': -20},\n",
       "  'id': 'call_PD5SuJLkNIUYvYREKwtxUj0r'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Whats 119 times 8 minus 20. Don't do any math yourself, only use tools for math. Respect order of operations\"\n",
    "\n",
    "llm_with_tools.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above result, it shouldn't call the add method since we have not invoked the multiply method yet.\n",
    "#### This problem can be solved with Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'call_eUpUCx6PNzjaGlK2ADcfu90W'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    HumanMessage(\"What's the product of 317253 and 128472 plus four\", name=\"example_user\"),\n",
    "    AIMessage(content=\"\", \n",
    "              name=\"example_assistant\",\n",
    "              tool_calls=[{\n",
    "                  \"name\":\"Multiply\",\n",
    "                  \"args\":{'a':317253, 'b':128472},\n",
    "                  \"id\":\"1\"\n",
    "              }]),\n",
    "    ToolMessage(\"40758127416\", tool_call_id=\"1\"),\n",
    "    AIMessage(content=\"\",\n",
    "              name = \"example_assistant\",\n",
    "              tool_calls=[{\n",
    "                  \"name\":\"Add\",\n",
    "                  \"args\":{'a':40758127416, 'b':4},\n",
    "                  \"id\":\"2\"\n",
    "              }]\n",
    "              ),\n",
    "    ToolMessage(\"40758127420\", tool_call_id=\"2\"),\n",
    "    AIMessage(content=\"The product of 317253 and 128472 plus 4 is 40758127420\")\n",
    "]\n",
    "\n",
    "\n",
    "system = \"\"\"You are really bad at math but good at using calculator.\n",
    "Use below tool usage as an example of how to correctly use the tools\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system),\n",
    "    *examples,\n",
    "    (\"human\",\"{query}\")\n",
    "])\n",
    "\n",
    "chain = {\"query\":RunnablePassthrough()}|few_shot_prompt|llm_with_tools\n",
    "chain.invoke(\"Whats 119 times 8 minus 20\").tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvLangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
