{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling say_hello\n",
      "say_hello took 0.000374 seconds to process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Saurabh, your age is 10.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Decorators Refresher\n",
    "\"\"\"\n",
    "By definition, a decorator is a function that takes another function \n",
    "and extends the behavior of the latter function without explicitly modifying it\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        starttime = time.perf_counter()\n",
    "        print(f\"Calling {func.__name__}\")\n",
    "        value = func(*args, **kwargs)\n",
    "        endtime = time.perf_counter()\n",
    "        time_taken = endtime - starttime\n",
    "        print(f\"{func.__name__} took {time_taken:4f} seconds to process\")\n",
    "        return value\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def say_hello(name,age):\n",
    "    return f\"Hello {name}, your age is {age}.\"\n",
    "\n",
    "say_hello(\"Saurabh\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @tool decorator\n",
    "Tool Decorator makes tools out of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is 1 way of doing things\n",
    "\"\"\"\n",
    "@tool\n",
    "def multiply(a: int, b:int)->int:\n",
    "    \"Multiply a & b\"\n",
    "    return a*b\n",
    "\n",
    "@tool\n",
    "def add(a:int, b:int)->int:\n",
    "    \"Add a & bs\"\n",
    "    return a+b\n",
    "\n",
    "tools = [multiply,add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_JBonyXD46fPCm48dcT1MArEA', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'Multiply'}, 'type': 'function'}, {'id': 'call_Gm8GOMP0BguwokTQzw2FdMHy', 'function': {'arguments': '{\"a\": 3, \"b\": 3}', 'name': 'Add'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 90, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-faf99777-2b78-4e3f-97ae-39fb6bd9d7b1-0' tool_calls=[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_JBonyXD46fPCm48dcT1MArEA'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_Gm8GOMP0BguwokTQzw2FdMHy'}]\n",
      "****************************************************************************************************\n",
      "[{'name': 'Multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_JBonyXD46fPCm48dcT1MArEA'}, {'name': 'Add', 'args': {'a': 3, 'b': 3}, 'id': 'call_Gm8GOMP0BguwokTQzw2FdMHy'}]\n",
      "LLM Result\n",
      "content='3*12 is equal to 36.\\n\\n3+3 is equal to 6.' response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 22, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-09101fc4-ea43-49e3-b518-a6e7b3c7cb15-0'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is 2nd way of doing things\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Add(BaseModel):\n",
    "    a:int=Field(...,description=\"First integer\")\n",
    "    b:int=Field(...,description=\"Second Integer\")\n",
    "\n",
    "class Multiply(BaseModel):\n",
    "    a:int=Field(...,description=\"First integer\")\n",
    "    b:int=Field(...,description=\"Second Integer\")\n",
    "\n",
    "tools = [Add, Multiply]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3*12? Also what is 3+3?\"\n",
    "\n",
    "\n",
    "# The role of LLM here is to just identify the right parameters and functions to call\n",
    "# LLM is not called using below line of code\n",
    "\n",
    "result = llm_with_tools.invoke(query)\n",
    "\n",
    "print(result)\n",
    "print(\"**\"*50)\n",
    "print(result.tool_calls)\n",
    "\n",
    "\n",
    "\n",
    "# To make a call to LLM and get result of a query, we have to call LLM.invoke\n",
    "\n",
    "print(f\"LLM Result\\n{llm.invoke(query)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvLangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
