{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What is a good name for a company that makes socks?\"\n",
    "messages = [HumanMessage(content=text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatModel - ChatOpenAI()\n",
    "<font color=\"blue\">\n",
    "    <ul>\n",
    "        <li>Chat Model takes a <b>list of HumanMessage(class)</b> as an input</li>\n",
    "        <li>Chat Model generates a <b>AIMessage</b> output</li>\n",
    "        <li>This <b>AIMessage can be converted into String Using StrOutputParser()</b></li>\n",
    "    </ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The co-founder of Microsoft is Bill Gates, alongside Paul Allen.' response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 30, 'total_tokens': 43}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None} id='run-b0c61e7f-ed2a-4564-adbc-7dc492d8791c-0'\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chat_response = chat_model.invoke(input=messages)\n",
    "print(chat_response)\n",
    "print(\"-----\"*50)\n",
    "print(type(chat_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM - OpenAI()\n",
    "<font color=\"blue\">\n",
    "<ul>\n",
    "    <li>LLM takes a <b>String</b>(HumanMessage or any message of type BaseMessage class) as an input</li>\n",
    "    <li>Chat Model generates a <b>Completion(String)</b> output</li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Socktopia\"\n",
      "2. \"SockWorks\"\n",
      "3. \"FootFrenzy\"\n",
      "4. \"SockSavvy\"\n",
      "5. \"ToeTreats\"\n",
      "6. \"HappyFeet Co.\"\n",
      "7. \"SockHaven\"\n",
      "8. \"SockMates\"\n",
      "9. \"PediPals\"\n",
      "10. \"SockSquad\"\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "llm_response = llm.invoke(\"What is langsmith?\")\n",
    "print(llm_response)\n",
    "print(\"----\"*50)\n",
    "print(type(llm_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
