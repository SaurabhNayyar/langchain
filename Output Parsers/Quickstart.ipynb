{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are Output Parsers?\n",
    "\n",
    "Language Models returns text. But sometimes, you may want to parse that text into some strucuture. Output Parsers are used in this case.\n",
    "\n",
    "Output Parsers are Classes that help structure language model responses.\n",
    "\n",
    "An OutputParser <b>must</b> implement following 2 methods:\n",
    "1. <b>Get Format Instructions</b> : Returns a string containing instructions for how the output of language model should be formatted.\n",
    "2. <b>Parse</b> : Takes input string and parses it into some structure.\n",
    "\n",
    "#### <b><u>Streaming with Parsers</u></b>\n",
    "\n",
    "While all parsers support the streaming interface, only certain parsers can stream through partially parsed objects, since this is highly dependent on the output type. Parsers which cannot construct partial objects will simply yield the fully parsed output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format instructions: \n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "print(f\"Format instructions: \\n{parser.get_format_instructions()}\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model | parser\n",
    "\n",
    "# PydanticOutputParser cannot stream \n",
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleJSONOutputParser can stream\n",
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "\n",
    "parser=SimpleJsonOutputParser()\n",
    "prompt = PromptTemplate.from_template(\"Answer the following question in JSON format:\\n {question}\")\n",
    "chain = prompt | model | parser\n",
    "output = chain.stream(\"Tell me a joke.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'joke': ''}\n",
      "{'joke': 'Why'}\n",
      "{'joke': 'Why don'}\n",
      "{'joke': \"Why don't scientists trust\"}\n",
      "{'joke': \"Why don't scientists trust atoms\"}\n",
      "{'joke': \"Why don't scientists trust atoms?\"}\n",
      "{'joke': \"Why don't scientists trust atoms? Because\"}\n",
      "{'joke': \"Why don't scientists trust atoms? Because they\"}\n",
      "{'joke': \"Why don't scientists trust atoms? Because they make up everything\"}\n",
      "{'joke': \"Why don't scientists trust atoms? Because they make up everything.\"}\n"
     ]
    }
   ],
   "source": [
    "for chunk in output:\n",
    "    print(chunk, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvLangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
